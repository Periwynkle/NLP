{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Test Set \n",
    "\n",
    "<b>*Note*</b>: I made two versions of the voting ensemble chunking classifier: one trained on 50,000 data points (~25% of the training dataset), the other on the full training dataset. The version trained on the full dataset is over twice the size of the version trained on 50,000 and takes far longer to run. Judging from the F1 scores of the other four classifiers after being trained on 90% of the training dataset, the improvement of performance is marginal (~1%). Each of these four classifiers, however, is smaller in size than that of the voting ensemble trained on 50,000 data points. As a point of comparison, the logistic regression model trained on 90% of the dataset is also provided, as the boxplot of accuracies after 10-fold cross-validation indicates that it has a similar accuracy to the voting ensemble.\n",
    "\n",
    "This script assumes that the test dataset filename is `chunking_test.txt`, that it is in a folder called Datasets (as this is the folder in which the training data was placed), and that the script is in the parent folder. These parameters can easily be modified should these assumptions not hold true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from nltk import word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_classifier = open('clf_ve_50000.pickle', 'rb')\n",
    "#saved_classifier = open('clf_lr_190554.pickle', 'rb')\n",
    "chunking_clf = pickle.load(saved_classifier) \n",
    "saved_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_set(filepath):\n",
    "    \n",
    "    df = pd.read_csv(filepath, sep=' ', header=None)\n",
    "    df.columns = ['token', 'pos_tag', 'chunk_tag']\n",
    "    y = df['chunk_tag']\n",
    "    X = []\n",
    "    \n",
    "    def features(token, index, pos_tag, chunk_tag):\n",
    "        features = {'token': token[index],\n",
    "                    'pos': pos_tag[index],\n",
    "                    'prev_token': '' if index == 0 else token[index-1],\n",
    "                    'prev_pos': '' if index == 0 else pos_tag[index-1],\n",
    "                    'prev_chunk': '' if index == 0 else chunk_tag[index-1],\n",
    "                    'next_token': '' if index == len(df.token)-1 else token[index+1],\n",
    "                    'next_pos': '' if index == len(df.token)-1 else pos_tag[index+1]}\n",
    "        return features\n",
    "\n",
    "    for index in range(len(df.token)):\n",
    "        X.append(features(df.token, index, df.pos_tag, df.chunk_tag))\n",
    "    \n",
    "    predicted = chunking_clf.predict(X)  \n",
    "    print(metrics.classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Datasets/chunking_test.txt'\n",
    "predict_on_test_set(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Texts\n",
    "\n",
    "As POS tags are an important input feature for the model, the NLTK library was used to automatically label them (other options are Stanford's CoreNLP and spaCy, but the former was decided against because it is more computationally intensive, and the latter was not chosen because there were issues downloading the `en_core_web_sm` model on Windows in an Anaconda environment). \n",
    "\n",
    "As the chunk tag of the previous token is also an input feature, *sequence classification* was used. More specifically, the *consecutive classification* approach was adopted: the chunk tag of the first token is used to determine the best tag for the second token, and so on and so forth.\n",
    "\n",
    "I compared the prediction results for two different text datasets, forum posts about cars from [scikit-learn's 20 Newsgroups](http://qwone.com/~jason/20Newsgroups/) and three random paragraphs from [a recent BBC article](https://www.bbc.co.uk/news/uk-politics-46227046), to determine the classifier's *domain versatility*. The forum posts are a stylistic contrast to edited text, which is what the classifier was trained on - they are messier in that they contain typos, special characters, and more slang. Thus, we would expect the classifier to perform better on news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "cars = fetch_20newsgroups(categories=['rec.autos'], remove=('headers', 'footers', 'quotes'))\n",
    "forum_posts = cars.data[70:73]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_paragraphs = ['She vowed to get the deal signed off in Brussels and put it to a vote of MPs.',\n",
    "'It follows a string of ministerial resignations and talk of a no-confidence vote from Tory MPs.',\n",
    "'Brexit Secretary Dominic Raab and Work and Pensions Secretary Esther McVey both quit earlier in protest at the withdrawal agreement, along with two junior ministers.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_texts(texts):\n",
    "    \n",
    "    texts = ' '.join(texts) # merge list of texts into one 'text'\n",
    "    texts = texts.replace('\\n',' ') # remove new lines\n",
    "    tokens = word_tokenize(texts) # list of tokens\n",
    "    token_pos_tag = pos_tag(tokens) # list of token, pos_tag tuples\n",
    "    chunk_tag_hist = []\n",
    "    \n",
    "    def pos(token_and_tag): # return a list of pos_tags from token, pos_tag tuples\n",
    "        return [t[1] for t in token_and_tag]\n",
    "    \n",
    "    def features(token, index, pos_tag, chunk_tag_hist): # chunk_tag_hist stores previously labelled chunk tags\n",
    "        features = {'token': token[index],\n",
    "                    'pos': pos_tag[index],\n",
    "                    'prev_token': '' if index == 0 else token[index-1],\n",
    "                    'prev_pos': '' if index == 0 else pos_tag[index-1],\n",
    "                    'prev_chunk': '' if index == 0 else chunk_tag_hist[index-1],\n",
    "                    'next_token': '' if index == len(token)-1 else token[index+1],\n",
    "                    'next_pos': '' if index == len(token)-1 else pos_tag[index+1]}\n",
    "        return features\n",
    "    \n",
    "    for index in range(len(tokens)):\n",
    "        X = features(tokens, index, pos(token_pos_tag), chunk_tag_hist)\n",
    "        predicted = chunking_clf.predict(X)\n",
    "        chunk_tag_hist.append(predicted[0]) # scikit-learn classifiers output 1D NumPy arrays\n",
    "\n",
    "    for token, predicted_tag in zip(tokens, chunk_tag_hist):\n",
    "        print('%s => %s' % (token, predicted_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_texts(forum_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_texts(news_paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "A version of the `predict_on_texts` function without sequential (consecutive) classification was also produced to better understand the difference that such an approach can make. Results are not as good, which is to be expected. The version with sequential classification is better at recognising named entity chunks. One example of a difference:\n",
    "\n",
    "With previous chunk tag:\n",
    "Brexit => B-NP\n",
    "Secretary => I-NP\n",
    "Dominic => I-NP\n",
    "Raab => I-NP\n",
    "\n",
    "Without previous chunk tag:\n",
    "Brexit => B-NP\n",
    "Secretary => B-NP\n",
    "Dominic => B-NP\n",
    "Raab => B-NP\n",
    "\n",
    "'And' is often misclassified as 'O'. This is a problem that needs to be addressed in future iterations of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_texts2(texts):\n",
    "    \n",
    "    texts = ' '.join(texts) # merge list of texts into one 'text'\n",
    "    texts = texts.replace('\\n',' ') # remove new lines\n",
    "    tokens = word_tokenize(texts) # list of tokens\n",
    "    token_pos_tag = pos_tag(tokens) # list of token, pos_tag tuples\n",
    "    X = []\n",
    "    \n",
    "    def pos(token_and_tag): # return a list of pos_tags from token, pos_tag tuples\n",
    "        return [t[1] for t in token_and_tag]\n",
    "    \n",
    "    def features(token, index, pos_tag):\n",
    "        features = {'token': token[index],\n",
    "                    'pos': pos_tag[index],\n",
    "                    'prev_token': '' if index == 0 else token[index-1],\n",
    "                    'prev_pos': '' if index == 0 else pos_tag[index-1],\n",
    "                    'next_token': '' if index == len(token)-1 else token[index+1],\n",
    "                    'next_pos': '' if index == len(token)-1 else pos_tag[index+1]}\n",
    "        return features\n",
    "    \n",
    "    for index in range(len(tokens)):\n",
    "        X.append(features(tokens, index, pos(token_pos_tag)))\n",
    "    \n",
    "    predicted = chunking_clf.predict(X) \n",
    "    \n",
    "    for token, predicted_tag in zip(tokens, predicted):\n",
    "        print('%s => %s' % (token, predicted_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_texts2(sample_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_on_texts2(news_paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
